{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a5a1ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maximos/miniconda3/envs/torch/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from data_utils import CSGridMLMDataset, CSGridMLM_collate_fn\n",
    "from GridMLM_tokenizers import CSGridMLMTokenizer\n",
    "import os\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from models import DualGridMLMMelHarm, SEModular\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from torch.nn import CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d881cd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "curriculum_type = 'f2f'\n",
    "exponent = 5\n",
    "subfolder = 'Q4_L80_bar_PC'\n",
    "train_dir = '/media/maindisk/data/synthetic_CA_train'\n",
    "val_dir = '/media/maindisk/data/synthetic_CA_test'\n",
    "device_name = 'cpu'\n",
    "epochs = 200\n",
    "lr = 1e-4\n",
    "batchsize = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dac059ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_stages = None if curriculum_type == 'f2f' else 10\n",
    "condition_dim = None if 'bar' in subfolder else 16\n",
    "trainable_pos_emb = False\n",
    "\n",
    "grid_lenght = int(subfolder.split('_L')[1].split('_')[0])\n",
    "tokenizer = CSGridMLMTokenizer(\n",
    "    fixed_length=grid_lenght,\n",
    "    quantization='16th' if 'Q16' in subfolder else '4th',\n",
    "    intertwine_bar_info='bar' in subfolder,\n",
    "    trim_start=False,\n",
    "    use_pc_roll='PC' in subfolder,\n",
    "    use_full_range_melody='FR' in subfolder\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "841c53e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data file.\n",
      "Loading data file.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = CSGridMLMDataset(train_dir, tokenizer, name_suffix=subfolder)\n",
    "val_dataset = CSGridMLMDataset(val_dir, tokenizer, name_suffix=subfolder)\n",
    "\n",
    "trainloader = DataLoader(train_dataset, batch_size=batchsize, shuffle=True, collate_fn=CSGridMLM_collate_fn)\n",
    "valloader = DataLoader(val_dataset, batch_size=batchsize, shuffle=False, collate_fn=CSGridMLM_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25d050e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if device_name == 'cpu':\n",
    "    device = torch.device('cpu')\n",
    "else:\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(device_name)\n",
    "    else:\n",
    "        print('Selected device not available: ' + device_name)\n",
    "# end device selection\n",
    "\n",
    "loss_fn=CrossEntropyLoss(ignore_index=-100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cad2f22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DualGridMLMMelHarm(\n",
    "    chord_vocab_size=len(tokenizer.vocab),\n",
    "    d_model=512,\n",
    "    nhead=8,\n",
    "    num_layers_mel=8,\n",
    "    num_layers_harm=8,\n",
    "    melody_length=grid_lenght,\n",
    "    harmony_length=grid_lenght,\n",
    "    pianoroll_dim=tokenizer.pianoroll_dim,\n",
    "    device=device,\n",
    ")\n",
    "# model = SEModular(\n",
    "#     chord_vocab_size=len(tokenizer.vocab),\n",
    "#     d_model=512,\n",
    "#     nhead=8,\n",
    "#     num_layers=8,\n",
    "#     grid_length=grid_lenght,\n",
    "#     pianoroll_dim=tokenizer.pianoroll_dim,\n",
    "#     condition_dim=condition_dim,  # if not None, add a condition token of this dim at start\n",
    "#     unmasking_stages=total_stages,  # if not None, use stage-based unmasking\n",
    "#     trainable_pos_emb=trainable_pos_emb,\n",
    "#     device=device,\n",
    "# )\n",
    "model.to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58986095",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "504736ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  6, 210, 269, 329, 152,   6, 124, 124, 269,   7,   6, 329,   7, 210,\n",
      "         269,   6,  66, 124, 269,   7,   6,  66, 124, 210, 329,   6, 269, 329,\n",
      "          66,   7,   6, 329, 210,  66,   7,   6, 152, 269, 210,   7,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  6,  66, 124, 329, 124,   6, 210, 269, 124, 269,   6, 152, 329, 210,\n",
      "          66,   6, 152, 329, 124, 210,   6,   7,  66, 329, 269,   6, 329, 269,\n",
      "         329, 152,   6,   7, 210, 329, 329,   6, 152, 210,   7, 152,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  6,  66, 329, 152, 210,   6, 124,  66,  66,   7,   6, 269, 152, 269,\n",
      "         210,   6,   7,  66,  66,   7,   6, 152, 329, 124, 152,   6, 329, 269,\n",
      "         269, 269,   6, 152, 329, 124,  66,   6,  66,   7, 152, 269,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  6, 210, 269, 329, 329,   6, 152, 269, 329, 152,   6, 329,   7, 210,\n",
      "         124,   6, 152, 210, 210, 269,   6, 269, 152, 329,   7,   6,  66,  66,\n",
      "          66, 329,   6, 210, 329, 210, 124,   6, 329,   7, 269, 210,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  6, 329, 152,  66, 152,   6, 269, 124, 124,  66,   6, 210, 210,   7,\n",
      "          66,   6, 124, 124, 124, 329,   6,   7, 329, 329,  66,   6,   7, 329,\n",
      "         329, 210,   6, 210, 124, 269, 124,   6,   7, 210, 329,   7,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  6, 329, 124,   7, 124,   6, 210, 124, 124, 124,   6,  66,  66, 152,\n",
      "         210,   6,  66, 152, 329,  66,   6,  66,   7,   7, 152,   6, 124,  66,\n",
      "           7, 210,   6,   7, 269,   7, 329,   6,   7, 152,  66, 329,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  6, 152,  66, 152, 329,   6, 329, 210, 124, 329,   6, 210,   7, 329,\n",
      "         269,   6,  66, 269, 210,  66,   6, 210, 152, 124, 152,   6, 210, 124,\n",
      "         124, 124,   6, 210, 210, 124, 269,   6,   7,   7, 152, 269,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  6, 124, 269,   7, 269,   6, 124, 152, 124, 269,   6, 124, 152, 269,\n",
      "         124,   6, 329, 124, 152, 152,   6,   7, 269, 329,  66,   6, 329,  66,\n",
      "         269,   7,   6, 329,   7, 210, 124,   6, 152, 152,  66, 329,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1]])\n"
     ]
    }
   ],
   "source": [
    "harmony_gt = batch[\"harmony_ids\"].to(device)\n",
    "print(harmony_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bcd1ea1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_to_partial_masking(\n",
    "        harmony_tokens,\n",
    "        mask_token_id,\n",
    "        num_visible=0,\n",
    "        bar_token_id=None\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Generate visible input and denoising target for diffusion-style training.\n",
    "\n",
    "    Args:\n",
    "        harmony_tokens (torch.Tensor): Tensor of shape (B, L) containing target harmony token ids.\n",
    "        stage (int): Current training stage (0 to total_stages - 1).\n",
    "        total_stages (int): Total number of diffusion stages.\n",
    "        mask_token_id (int): The token ID used to mask hidden positions in visible_harmony.\n",
    "        device (str or torch.device): Target device.\n",
    "\n",
    "    Returns:\n",
    "        visible_harmony (torch.Tensor): Tensor of shape (B, L) with visible tokens (others masked).\n",
    "        denoising_target (torch.Tensor): Tensor of shape (B, L) with tokens to predict (others = -100).\n",
    "    \"\"\"\n",
    "    device = harmony_tokens.device\n",
    "    B, L = harmony_tokens.shape\n",
    "\n",
    "    visible_harmony = torch.full_like(harmony_tokens, fill_value=mask_token_id)\n",
    "    denoising_target = torch.full_like(harmony_tokens, fill_value=-100)  # -100 is ignored by CrossEntropyLoss\n",
    "\n",
    "    if bar_token_id is not None:\n",
    "        # Create a mask for bar token positions\n",
    "        bar_mask = (harmony_tokens == bar_token_id)\n",
    "        # Put bar tokens in visible_harmony (always unmasked)\n",
    "        visible_harmony[bar_mask] = bar_token_id\n",
    "        # # Also include them in the denoising target (so model predicts them too)\n",
    "        denoising_target[bar_mask] = bar_token_id\n",
    "    \n",
    "    perm = torch.randperm(L, device=device)\n",
    "\n",
    "    visible_idx = perm[:num_visible]\n",
    "    predict_idx = perm[num_visible:]  # predict all remaining\n",
    "    # print('visible_idx: ', visible_idx)\n",
    "    # print('predict_idx: ', predict_idx)\n",
    "\n",
    "    visible_harmony[:, visible_idx] = harmony_tokens[:, visible_idx]\n",
    "    denoising_target[:, predict_idx] = harmony_tokens[:, predict_idx]\n",
    "\n",
    "    # visible_harmony = harmony_tokens.clone()\n",
    "    # visible_harmony[:, :] = mask_token_id\n",
    "    # # visible_harmony[:, 0:10] = mask_token_id\n",
    "    # denoising_target = harmony_tokens.clone()  # -100 is ignored by CrossEntropyLoss\n",
    "    # # denoising_target[:, 10:] = -100\n",
    "\n",
    "    return visible_harmony, denoising_target\n",
    "# end full_to_partial_masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "247c387c",
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 0\n",
    "total_steps = 1000\n",
    "percent_visible = min(1.0, (step+1)/total_steps)**exponent  # 5th power goes around half way near zero\n",
    "L = harmony_gt.shape[1]\n",
    "num_visible = min( int(L * percent_visible), L-1 )  # ensure at least one token is predicted\n",
    "harmony_input, harmony_target = full_to_partial_masking(\n",
    "    harmony_gt,\n",
    "    tokenizer.mask_token_id,\n",
    "    num_visible,\n",
    "    bar_token_id=tokenizer.bar_token_id\n",
    ")\n",
    "stage_indices = None\n",
    "conditioning_vec = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67cbf76b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6, 5, 5, 5, 5, 6, 5, 5, 5, 5, 6, 5, 5, 5, 5, 6, 5, 5, 5, 5, 6, 5, 5, 5,\n",
      "        5, 6, 5, 5, 5, 5, 6, 5, 5, 5, 5, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5])\n",
      "tensor([  6, 210, 269, 329, 152,   6, 124, 124, 269,   7,   6, 329,   7, 210,\n",
      "        269,   6,  66, 124, 269,   7,   6,  66, 124, 210, 329,   6, 269, 329,\n",
      "         66,   7,   6, 329, 210,  66,   7,   6, 152, 269, 210,   7,   1,   1,\n",
      "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1])\n"
     ]
    }
   ],
   "source": [
    "print(harmony_input[0])\n",
    "print(harmony_gt[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a9b216dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = model(\n",
    "    # melody_grid.to(device),\n",
    "    harmony_gt.to(device),\n",
    "    harmony_input.to(device),\n",
    "    conditioning_vec,\n",
    "    stage_indices\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de5c1e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([80, 355])\n"
     ]
    }
   ],
   "source": [
    "print(logits[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "15e6f7a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6083, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "loss = loss_fn(logits.view(-1, logits.size(-1)), harmony_target.view(-1))\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7dbeaf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
