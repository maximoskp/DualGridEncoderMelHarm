{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fdee4da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maximos/miniconda3/envs/torch/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torcheval.metrics.text import Perplexity\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from data_utils import compute_normalized_token_entropy\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "from data_utils import CSGridMLMDataset, CSGridMLM_collate_fn\n",
    "from GridMLM_tokenizers import CSGridMLMTokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "from models import DualGridMLMMelHarm\n",
    "from torch.optim import AdamW\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from train_utils import train_with_curriculum, apply_masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c19e70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = CSGridMLMTokenizer(\n",
    "    fixed_length=80,\n",
    "    quantization='4th',\n",
    "    intertwine_bar_info=True,\n",
    "    trim_start=False,\n",
    "    use_pc_roll=True,\n",
    "    use_full_range_melody=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b7c3210",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '/media/maindisk/data/synthetic_CA_train'\n",
    "val_dir = '/media/maindisk/data/synthetic_CA_test'\n",
    "batchsize = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b40167f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data file.\n",
      "Loading data file.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = CSGridMLMDataset(train_dir, tokenizer, name_suffix='DE')\n",
    "val_dataset = CSGridMLMDataset(val_dir, tokenizer, name_suffix='DE')\n",
    "\n",
    "trainloader = DataLoader(train_dataset, batch_size=batchsize, shuffle=True, collate_fn=CSGridMLM_collate_fn)\n",
    "valloader = DataLoader(val_dataset, batch_size=batchsize, shuffle=False, collate_fn=CSGridMLM_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffc358a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device_name = 'cuda:0'\n",
    "if device_name == 'cpu':\n",
    "    device = torch.device('cpu')\n",
    "else:\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(device_name)\n",
    "    else:\n",
    "        print('Selected device not available: ' + device_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d409e544",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn=CrossEntropyLoss(ignore_index=-100)\n",
    "lr = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f86b134",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_stages = 10\n",
    "\n",
    "model = DualGridMLMMelHarm(\n",
    "    chord_vocab_size=len(tokenizer.vocab),\n",
    "    d_model=512,\n",
    "    nhead=8,\n",
    "    num_layers_mel=8,\n",
    "    num_layers_harm=8,\n",
    "    melody_length=80,\n",
    "    harmony_length=80,\n",
    "    max_stages=total_stages,\n",
    "    pianoroll_dim=tokenizer.pianoroll_dim,\n",
    "    device=device\n",
    ")\n",
    "model.to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bf045f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DualGridMLMMelHarm(\n",
       "  (melody_proj): Linear(in_features=13, out_features=512, bias=True)\n",
       "  (harmony_embedding): Embedding(355, 512)\n",
       "  (stage_embedding): Embedding(10, 64)\n",
       "  (stage_proj): Linear(in_features=576, out_features=512, bias=True)\n",
       "  (melody_encoder): SimpleTransformerStack(\n",
       "    (layers): ModuleList(\n",
       "      (0-7): 8 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.3, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.3, inplace=False)\n",
       "        (dropout2): Dropout(p=0.3, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (harmony_encoder): HarmonyTransformerStack(\n",
       "    (layers): ModuleList(\n",
       "      (0-7): 8 x HarmonyEncoderLayerWithCross(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (cross_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (activation): GELU(approximate='none')\n",
       "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.3, inplace=False)\n",
       "        (dropout2): Dropout(p=0.3, inplace=False)\n",
       "        (dropout3): Dropout(p=0.3, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (output_head): Linear(in_features=512, out_features=355, bias=True)\n",
       "  (input_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  (output_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(trainloader))\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a5a7eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "melody_grid = batch[\"pianoroll\"].to(device)           # (B, 256, 100)\n",
    "harmony_gt = batch[\"input_ids\"].to(device)         # (B, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6543e640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 80, 13])\n",
      "torch.Size([2, 80])\n"
     ]
    }
   ],
   "source": [
    "print(melody_grid.shape)\n",
    "print(harmony_gt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e603159",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_token_id = tokenizer.mask_token_id\n",
    "bar_token_id = tokenizer.bar_token_id\n",
    "curriculum_type = 'random'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70e07f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "visible_idx:  tensor([], device='cuda:0', dtype=torch.int64)\n",
      "predict_idx:  tensor([12, 18, 49, 72, 21,  9, 24, 52], device='cuda:0')\n",
      "visible_idx:  tensor([22,  0, 76, 31,  9, 71, 41, 77, 49, 66, 48,  8, 60, 47, 15, 29, 55, 28,\n",
      "        26, 38, 72, 20, 19, 17,  6, 11, 27, 56, 59,  4, 53, 14, 50, 64, 42, 61,\n",
      "        62, 51, 67, 21, 74, 36, 69, 30, 25, 75,  2, 35, 44, 58, 16, 12, 54, 65,\n",
      "         5, 34, 45,  3, 57, 78, 63, 13, 68, 70], device='cuda:0')\n",
      "predict_idx:  tensor([22,  0, 76, 31,  9, 71, 41, 77, 49, 66, 48,  8, 60, 47, 15, 29, 55, 28,\n",
      "        26, 38, 72, 20, 19, 17,  6, 11, 27, 56, 59,  4, 53, 14, 50, 64, 42, 61,\n",
      "        62, 51, 67, 21, 74, 36, 69, 30, 25, 75,  2, 35, 44, 58, 16, 12, 54, 65,\n",
      "         5, 34, 45,  3, 57, 78, 63, 13, 68, 70, 73,  1, 18, 40, 23, 37, 46, 10],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "rets = apply_masking(\n",
    "    harmony_gt,\n",
    "    mask_token_id,\n",
    "    total_stages=total_stages,\n",
    "    curriculum_type=curriculum_type,\n",
    "    bar_token_id=bar_token_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4a648b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "harmony_input, harmony_target, stage_indices = rets[0], rets[1], rets[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ce51d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 6 -100\n",
      "210 5 -100\n",
      "269 5 -100\n",
      "210 5 -100\n",
      "7 5 -100\n",
      "6 6 -100\n",
      "152 5 -100\n",
      "269 5 -100\n",
      "269 5 -100\n",
      "7 5 7\n",
      "6 6 -100\n",
      "7 5 -100\n",
      "329 5 329\n",
      "7 5 -100\n",
      "210 5 -100\n",
      "6 6 -100\n",
      "152 5 -100\n",
      "7 5 -100\n",
      "7 5 7\n",
      "124 5 -100\n",
      "6 6 -100\n",
      "329 5 329\n",
      "66 5 -100\n",
      "210 5 -100\n",
      "7 5 7\n",
      "6 6 -100\n",
      "269 5 -100\n",
      "7 5 -100\n",
      "269 5 -100\n",
      "329 5 -100\n",
      "6 6 -100\n",
      "210 5 -100\n",
      "210 5 -100\n",
      "124 5 -100\n",
      "7 5 -100\n",
      "6 6 -100\n",
      "152 5 -100\n",
      "152 5 -100\n",
      "66 5 -100\n",
      "124 5 -100\n",
      "1 5 -100\n",
      "1 5 -100\n",
      "1 5 -100\n",
      "1 5 -100\n",
      "1 5 -100\n",
      "1 5 -100\n",
      "1 5 -100\n",
      "1 5 -100\n",
      "1 5 -100\n",
      "1 5 1\n",
      "1 5 -100\n",
      "1 5 -100\n",
      "1 5 1\n",
      "1 5 -100\n",
      "1 5 -100\n",
      "1 5 -100\n",
      "1 5 -100\n",
      "1 5 -100\n",
      "1 5 -100\n",
      "1 5 -100\n",
      "1 5 -100\n",
      "1 5 -100\n",
      "1 5 -100\n",
      "1 5 -100\n",
      "1 5 -100\n",
      "1 5 -100\n",
      "1 5 -100\n",
      "1 5 -100\n",
      "1 5 -100\n",
      "1 5 -100\n",
      "1 5 -100\n",
      "1 5 -100\n",
      "1 5 1\n",
      "1 5 -100\n",
      "1 5 -100\n",
      "1 5 -100\n",
      "1 5 -100\n",
      "1 5 -100\n",
      "1 5 -100\n",
      "1 5 -100\n"
     ]
    }
   ],
   "source": [
    "# print(harmony_input[0,:])\n",
    "# print(harmony_target[0,:])\n",
    "# print(stage_indices)\n",
    "for i in range(harmony_input.shape[1]):\n",
    "    print(harmony_gt[0][i].item(), harmony_input[0,i].item(), harmony_target[0,i].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b993154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<unk>': 0, '<pad>': 1, '<s>': 2, '</s>': 3, '<nc>': 4, '<mask>': 5, '<bar>': 6, 'C:maj': 7, 'C:min': 8, 'C:aug': 9, 'C:dim': 10, 'C:sus4': 11, 'C:sus2': 12, 'C:7': 13, 'C:maj7': 14, 'C:min7': 15, 'C:minmaj7': 16, 'C:maj6': 17, 'C:min6': 18, 'C:dim7': 19, 'C:hdim7': 20, 'C:maj9': 21, 'C:min9': 22, 'C:9': 23, 'C:min11': 24, 'C:11': 25, 'C:maj13': 26, 'C:min13': 27, 'C:13': 28, 'C:1': 29, 'C:5': 30, 'C': 31, 'C:7(b9)': 32, 'C:7(#9)': 33, 'C:7(#11)': 34, 'C:7(b13)': 35, 'C#:maj': 36, 'C#:min': 37, 'C#:aug': 38, 'C#:dim': 39, 'C#:sus4': 40, 'C#:sus2': 41, 'C#:7': 42, 'C#:maj7': 43, 'C#:min7': 44, 'C#:minmaj7': 45, 'C#:maj6': 46, 'C#:min6': 47, 'C#:dim7': 48, 'C#:hdim7': 49, 'C#:maj9': 50, 'C#:min9': 51, 'C#:9': 52, 'C#:min11': 53, 'C#:11': 54, 'C#:maj13': 55, 'C#:min13': 56, 'C#:13': 57, 'C#:1': 58, 'C#:5': 59, 'C#': 60, 'C#:7(b9)': 61, 'C#:7(#9)': 62, 'C#:7(#11)': 63, 'C#:7(b13)': 64, 'D:maj': 65, 'D:min': 66, 'D:aug': 67, 'D:dim': 68, 'D:sus4': 69, 'D:sus2': 70, 'D:7': 71, 'D:maj7': 72, 'D:min7': 73, 'D:minmaj7': 74, 'D:maj6': 75, 'D:min6': 76, 'D:dim7': 77, 'D:hdim7': 78, 'D:maj9': 79, 'D:min9': 80, 'D:9': 81, 'D:min11': 82, 'D:11': 83, 'D:maj13': 84, 'D:min13': 85, 'D:13': 86, 'D:1': 87, 'D:5': 88, 'D': 89, 'D:7(b9)': 90, 'D:7(#9)': 91, 'D:7(#11)': 92, 'D:7(b13)': 93, 'D#:maj': 94, 'D#:min': 95, 'D#:aug': 96, 'D#:dim': 97, 'D#:sus4': 98, 'D#:sus2': 99, 'D#:7': 100, 'D#:maj7': 101, 'D#:min7': 102, 'D#:minmaj7': 103, 'D#:maj6': 104, 'D#:min6': 105, 'D#:dim7': 106, 'D#:hdim7': 107, 'D#:maj9': 108, 'D#:min9': 109, 'D#:9': 110, 'D#:min11': 111, 'D#:11': 112, 'D#:maj13': 113, 'D#:min13': 114, 'D#:13': 115, 'D#:1': 116, 'D#:5': 117, 'D#': 118, 'D#:7(b9)': 119, 'D#:7(#9)': 120, 'D#:7(#11)': 121, 'D#:7(b13)': 122, 'E:maj': 123, 'E:min': 124, 'E:aug': 125, 'E:dim': 126, 'E:sus4': 127, 'E:sus2': 128, 'E:7': 129, 'E:maj7': 130, 'E:min7': 131, 'E:minmaj7': 132, 'E:maj6': 133, 'E:min6': 134, 'E:dim7': 135, 'E:hdim7': 136, 'E:maj9': 137, 'E:min9': 138, 'E:9': 139, 'E:min11': 140, 'E:11': 141, 'E:maj13': 142, 'E:min13': 143, 'E:13': 144, 'E:1': 145, 'E:5': 146, 'E': 147, 'E:7(b9)': 148, 'E:7(#9)': 149, 'E:7(#11)': 150, 'E:7(b13)': 151, 'F:maj': 152, 'F:min': 153, 'F:aug': 154, 'F:dim': 155, 'F:sus4': 156, 'F:sus2': 157, 'F:7': 158, 'F:maj7': 159, 'F:min7': 160, 'F:minmaj7': 161, 'F:maj6': 162, 'F:min6': 163, 'F:dim7': 164, 'F:hdim7': 165, 'F:maj9': 166, 'F:min9': 167, 'F:9': 168, 'F:min11': 169, 'F:11': 170, 'F:maj13': 171, 'F:min13': 172, 'F:13': 173, 'F:1': 174, 'F:5': 175, 'F': 176, 'F:7(b9)': 177, 'F:7(#9)': 178, 'F:7(#11)': 179, 'F:7(b13)': 180, 'F#:maj': 181, 'F#:min': 182, 'F#:aug': 183, 'F#:dim': 184, 'F#:sus4': 185, 'F#:sus2': 186, 'F#:7': 187, 'F#:maj7': 188, 'F#:min7': 189, 'F#:minmaj7': 190, 'F#:maj6': 191, 'F#:min6': 192, 'F#:dim7': 193, 'F#:hdim7': 194, 'F#:maj9': 195, 'F#:min9': 196, 'F#:9': 197, 'F#:min11': 198, 'F#:11': 199, 'F#:maj13': 200, 'F#:min13': 201, 'F#:13': 202, 'F#:1': 203, 'F#:5': 204, 'F#': 205, 'F#:7(b9)': 206, 'F#:7(#9)': 207, 'F#:7(#11)': 208, 'F#:7(b13)': 209, 'G:maj': 210, 'G:min': 211, 'G:aug': 212, 'G:dim': 213, 'G:sus4': 214, 'G:sus2': 215, 'G:7': 216, 'G:maj7': 217, 'G:min7': 218, 'G:minmaj7': 219, 'G:maj6': 220, 'G:min6': 221, 'G:dim7': 222, 'G:hdim7': 223, 'G:maj9': 224, 'G:min9': 225, 'G:9': 226, 'G:min11': 227, 'G:11': 228, 'G:maj13': 229, 'G:min13': 230, 'G:13': 231, 'G:1': 232, 'G:5': 233, 'G': 234, 'G:7(b9)': 235, 'G:7(#9)': 236, 'G:7(#11)': 237, 'G:7(b13)': 238, 'G#:maj': 239, 'G#:min': 240, 'G#:aug': 241, 'G#:dim': 242, 'G#:sus4': 243, 'G#:sus2': 244, 'G#:7': 245, 'G#:maj7': 246, 'G#:min7': 247, 'G#:minmaj7': 248, 'G#:maj6': 249, 'G#:min6': 250, 'G#:dim7': 251, 'G#:hdim7': 252, 'G#:maj9': 253, 'G#:min9': 254, 'G#:9': 255, 'G#:min11': 256, 'G#:11': 257, 'G#:maj13': 258, 'G#:min13': 259, 'G#:13': 260, 'G#:1': 261, 'G#:5': 262, 'G#': 263, 'G#:7(b9)': 264, 'G#:7(#9)': 265, 'G#:7(#11)': 266, 'G#:7(b13)': 267, 'A:maj': 268, 'A:min': 269, 'A:aug': 270, 'A:dim': 271, 'A:sus4': 272, 'A:sus2': 273, 'A:7': 274, 'A:maj7': 275, 'A:min7': 276, 'A:minmaj7': 277, 'A:maj6': 278, 'A:min6': 279, 'A:dim7': 280, 'A:hdim7': 281, 'A:maj9': 282, 'A:min9': 283, 'A:9': 284, 'A:min11': 285, 'A:11': 286, 'A:maj13': 287, 'A:min13': 288, 'A:13': 289, 'A:1': 290, 'A:5': 291, 'A': 292, 'A:7(b9)': 293, 'A:7(#9)': 294, 'A:7(#11)': 295, 'A:7(b13)': 296, 'A#:maj': 297, 'A#:min': 298, 'A#:aug': 299, 'A#:dim': 300, 'A#:sus4': 301, 'A#:sus2': 302, 'A#:7': 303, 'A#:maj7': 304, 'A#:min7': 305, 'A#:minmaj7': 306, 'A#:maj6': 307, 'A#:min6': 308, 'A#:dim7': 309, 'A#:hdim7': 310, 'A#:maj9': 311, 'A#:min9': 312, 'A#:9': 313, 'A#:min11': 314, 'A#:11': 315, 'A#:maj13': 316, 'A#:min13': 317, 'A#:13': 318, 'A#:1': 319, 'A#:5': 320, 'A#': 321, 'A#:7(b9)': 322, 'A#:7(#9)': 323, 'A#:7(#11)': 324, 'A#:7(b13)': 325, 'B:maj': 326, 'B:min': 327, 'B:aug': 328, 'B:dim': 329, 'B:sus4': 330, 'B:sus2': 331, 'B:7': 332, 'B:maj7': 333, 'B:min7': 334, 'B:minmaj7': 335, 'B:maj6': 336, 'B:min6': 337, 'B:dim7': 338, 'B:hdim7': 339, 'B:maj9': 340, 'B:min9': 341, 'B:9': 342, 'B:min11': 343, 'B:11': 344, 'B:maj13': 345, 'B:min13': 346, 'B:13': 347, 'B:1': 348, 'B:5': 349, 'B': 350, 'B:7(b9)': 351, 'B:7(#9)': 352, 'B:7(#11)': 353, 'B:7(b13)': 354}\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.vocab)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
